{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine ESM-Inpaintign pipeline\n",
    "\n",
    "Key point : ground truth backbone frame be fed into structure module rather than to use black hole initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import esm\n",
    "import numpy as np\n",
    "import esm_inpaint.esm.esmfold.v1.esmfold as ESM\n",
    "import esm_inpaint.utils as utils\n",
    "import esm_inpaint.modules as modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.28930830039526\n"
     ]
    }
   ],
   "source": [
    "# origin esmfold\n",
    "\n",
    "model = esm.pretrained.esmfold_v1()\n",
    "model = model.eval().cuda()\n",
    "\n",
    "# Optionally, uncomment to set a chunk size for axial attention. This can help reduce memory.\n",
    "# Lower sizes will have lower memory requirements at the cost of increased speed.\n",
    "# model.set_chunk_size(128)\n",
    "\n",
    "sequence = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
    "# Multimer prediction can be done with chains separated by ':'\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.infer_pdb(sequence)\n",
    "\n",
    "with open(\"result.pdb\", \"w\") as f:\n",
    "    f.write(output)\n",
    "\n",
    "import biotite.structure.io as bsio\n",
    "struct = bsio.load_structure(\"result.pdb\", extra_fields=[\"b_factor\"])\n",
    "print(struct.b_factor.mean())  # this will be the pLDDT\n",
    "# 88.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. class esmfold \n",
    "- self.lm_head 输出序列 已经有了\n",
    "- self.distance_embedding 给pair-wise 输入结构，需要自己定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/root/.cache/torch/hub/checkpoints/esmfold_3B_v1.pt\"\n",
    "model_data = torch.load(str(model_path), map_location=\"cpu\") #读取一个pickle文件为一个dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = model_data[\"cfg\"][\"model\"]\n",
    "model_state = model_data[\"model\"]\n",
    "model = ESM.ESMFold(esmfold_config=cfg)\n",
    "model.load_state_dict(model_state, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_data = utils.load_jsonl(\"./esm_inpaint/data/chain_set.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.from_numpy(np.stack([i for i in esm_data[0]['coords'].values()],axis=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan]],\n",
       "\n",
       "         [[    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan]],\n",
       "\n",
       "         [[    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan],\n",
       "          [    nan,     nan,     nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[10.3340, 38.2370, 18.8380],\n",
       "          [11.5050, 37.8970, 19.6330],\n",
       "          [12.6560, 37.2870, 18.8430],\n",
       "          [13.4520, 36.5200, 19.3900]],\n",
       "\n",
       "         [[12.7790, 37.6800, 17.5800],\n",
       "          [13.8600, 37.1940, 16.7440],\n",
       "          [15.1600, 37.9140, 17.0640],\n",
       "          [15.1860, 39.1280, 17.2060]],\n",
       "\n",
       "         [[16.2050, 37.1030, 17.2270],\n",
       "          [17.5680, 37.4520, 17.6440],\n",
       "          [17.7590, 37.1340, 19.1240],\n",
       "          [18.6790, 36.3400, 19.4270]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_rotation,bb_translation = utils.get_bb_frames(test_data)\n",
    "bb_frame = torch.zeros((*bb_rotation.shape[:-2],4,4))\n",
    "bb_frame[...,:3,:3] = bb_rotation\n",
    "bb_frame[...,:3,3] = bb_translation # [B, L, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openfold.utils.rigid_utils as rigid_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = rigid_utils.Rigid.from_tensor_4x4(bb_frame)\n",
    "rotate_points = frame[...,None].apply(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 330, 4, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 330, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_rotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 330, 1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_translation.unsqueeze(-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point : [B, L, n_p, 3]\n",
    "# frame : [B, L, 4, 4] tensor ---- slicing时应当转化为 [B, L, 1, 3, 3] \n",
    "# 对其 point [*, 3] ---- frame [*, 4,4]\n",
    "points = (test_data @ bb_rotation.transpose(-1,-2)) + bb_translation.unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = utils.nan_to_num(points)\n",
    "rotate_points = utils.nan_to_num(rotate_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(points - rotate_points) < 1e-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计模型参数\n",
    "\n",
    "esm2,2842768487(3B)  \n",
    "folding trunk,686106624(700M)    \n",
    "structure module,2019116(20M)    \n",
    "other,791655  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_total = 0\n",
    "trunk_block = 0\n",
    "trunk_sture_module = 0\n",
    "other = 0\n",
    "for i in model.state_dict().keys():\n",
    "    if i.startswith(\"esm\"):\n",
    "        esm_total += ((model.state_dict())[i]).numel()\n",
    "    elif i.startswith(\"trunk.blocks\"):\n",
    "        trunk_block += ((model.state_dict())[i]).numel()\n",
    "    elif i.startswith(\"trunk.structure_module\"):\n",
    "        trunk_sture_module += ((model.state_dict())[i]).numel()\n",
    "    else:\n",
    "        other += ((model.state_dict())[i]).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esm2 has 2842768487\n",
      "folding trunk has 686106624\n",
      "structure module has 2019116\n",
      "other has 791655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"esm2 has {esm_total}\\nfolding trunk has {trunk_block}\\nstructure module has {trunk_sture_module}\\nother has {other}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证ESM-Inpainting POC\n",
    "\n",
    "### 数据集构建 --- collate_batch + dataloader函数\n",
    "\n",
    "aa_type : 0-19\n",
    "\n",
    "x : 20 --- 只对输入有用\n",
    "\n",
    "padding : 21 --- 输入输出都有用  \n",
    "padding mask 的1表示这一块计算loss,0表示这一块不计算loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = [esm_data[i] for i in range(0,3)]\n",
    "batch_to_collate = []\n",
    "for i in range(len(batch_list)):\n",
    "    coord = np.stack([batch_list[i]['coords'][atom] for atom in batch_list[i]['coords'].keys()],axis=-2)\n",
    "    confidence = None\n",
    "    seq = batch_list[i][\"seq\"]\n",
    "    batch_to_collate.append((coord,confidence,seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "restypes = [\n",
    "    \"A\",\n",
    "    \"R\",\n",
    "    \"N\",\n",
    "    \"D\",\n",
    "    \"C\",\n",
    "    \"Q\",\n",
    "    \"E\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"L\",\n",
    "    \"K\",\n",
    "    \"M\",\n",
    "    \"F\",\n",
    "    \"P\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "    \"V\",\n",
    "]\n",
    "restype_order = {restype: i for i, restype in enumerate(restypes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = utils.CoordBatchConverter.collate_dense_tensors([torch.tensor(i[0]) for i in batch_to_collate],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = utils.CoordBatchConverter.collate_dense_tensors([torch.tensor([restype_order[res] for res in i[2]]) for i in batch_to_collate],21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_seq = 10\n",
    "bert_mask_fraction = np.random.uniform(low=0.5, high=0.8)\n",
    "bert_mask = torch.tensor([False for _ in range(10)] if np.random.random() < bert_mask_fraction else True) # 0, mask; 1 unmask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873464911436472"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_mask_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_mask = seq != 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = model_data[\"cfg\"][\"model\"]\n",
    "model = modules.esm_inpaint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = model_data[\"model\"]\n",
    "model.esmfold.load_state_dict(model_state, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esmfold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ac7c7a591b3b1c7843a2ac3c1da3475c2ffdc4684f266052d1e649f1d10700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
